{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d027d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\data\\\\pmis_sample.csv\")\n",
    "\n",
    "# Rename columns manually\n",
    "df = df.rename(columns={\n",
    "    \"EDUCATION\": \"Education\",\n",
    "    \"SKILL_1\": \"Skill no. 1\",\n",
    "    \"SKILL_2\": \"Skill no. 2\",\n",
    "    \"SKILL_3\": \"Skill no. 3\",\n",
    "    \"INTEREST\": \"Interest\",\n",
    "    \"LOCATION\": \"Location\",\n",
    "    \"INTERNSHIP\": \"Internship\"\n",
    "})\n",
    "\n",
    "# Save back to the same file (overwrite)\n",
    "df.to_csv(\"C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\data\\\\pmis_sample.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33172dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "✅ Best Hyperparameters:\n",
      "{'classifier__max_depth': None, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "✅ Model (pipeline) trained and saved as 'internship_model.pkl'\n",
      "✅ Cleaned training data saved as 'training_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================\n",
    "# 1. LOAD DATA\n",
    "# ============================\n",
    "df = pd.read_csv(\"C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\data\\\\pmis_sample.csv\")\n",
    "\n",
    "# Features & Target\n",
    "X = df[['Education', 'Skill no. 1', 'Skill no. 2', 'Skill no. 3', 'Interest', 'Location']]\n",
    "y = df['Internship']\n",
    "\n",
    "# ============================\n",
    "# 2. PIPELINE: Preprocessing + Model\n",
    "# ============================\n",
    "# Define categorical columns\n",
    "categorical_cols = X.columns.tolist()\n",
    "\n",
    "# Preprocessing: Impute missing values + OneHotEncode\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\" , drop = \"first\"))\n",
    "        ]), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Full pipeline = preprocessing + classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 3. GRID SEARCH\n",
    "# ============================\n",
    "param_grid = {\n",
    "    \"classifier__n_estimators\": [100, 200],\n",
    "    \"classifier__max_depth\": [None, 10, 20],\n",
    "    \"classifier__min_samples_split\": [2, 5],\n",
    "    \"classifier__min_samples_leaf\": [1, 2],\n",
    "    \"classifier__max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# ============================\n",
    "# 4. SAVE MODEL\n",
    "# ============================\n",
    "print(\"✅ Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "joblib.dump(best_model, \"C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\model\\\\internship_model.pkl\")\n",
    "df.to_csv(\"C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\data\\\\training_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Model (pipeline) trained and saved as 'internship_model.pkl'\")\n",
    "print(\"✅ Cleaned training data saved as 'training_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7249d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top_4_Internships': [{'Internship': 'Automation QA Intern'}, {'Internship': 'Agri Data Intern'}, {'Internship': 'Solar PV Intern'}, {'Internship': 'Learning Platform Intern'}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load trained pipeline model\n",
    "model = joblib.load('C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\model\\\\internship_model.pkl')\n",
    "\n",
    "# Load raw training dataset\n",
    "training_data = pd.read_csv('C:\\\\Code\\\\python\\\\sih\\\\back-end\\\\data\\\\pmis_sample.csv')\n",
    "\n",
    "def predict_internship(new_data_dict):\n",
    "    \"\"\"\n",
    "    Predicts internships for a user and returns JSON with only internship names.\n",
    "    \"\"\"\n",
    "    new_data = pd.DataFrame([new_data_dict])\n",
    "\n",
    "    # RULE-BASED condition (match on Education, Skills, Location)\n",
    "    condition = (\n",
    "        (training_data['Education'] == new_data.iloc[0]['Education']) &\n",
    "        (training_data['Skill no. 1'] == new_data.iloc[0]['Skill no. 1']) &\n",
    "        (training_data['Skill no. 2'] == new_data.iloc[0]['Skill no. 2']) &\n",
    "        (training_data['Skill no. 3'] == new_data.iloc[0]['Skill no. 3']) &\n",
    "        (training_data['Location'] == new_data.iloc[0]['Location'])\n",
    "    )\n",
    "    exact_matches = training_data[condition]\n",
    "\n",
    "    internships = []\n",
    "    if not exact_matches.empty:\n",
    "        internships = exact_matches['Internship'].drop_duplicates().tolist()\n",
    "\n",
    "    # If less than 4 → use ML predictions to fill remaining\n",
    "    if len(internships) < 4:\n",
    "        probs = model.predict_proba(new_data)[0]\n",
    "        top_idx = np.argsort(probs)[-4:][::-1]   # top 4\n",
    "        ml_preds = [model.classes_[i] for i in top_idx]\n",
    "\n",
    "        for pred in ml_preds:\n",
    "            if pred not in internships:\n",
    "                internships.append(pred)\n",
    "            if len(internships) == 4:\n",
    "                break\n",
    "\n",
    "    # Convert list into JSON objects (for frontend cards)\n",
    "    result = {\"Top_4_Internships\": [{\"Internship\": name} for name in internships]}\n",
    "    return result\n",
    "\n",
    "\n",
    "# =============================\n",
    "# HARDCODED TEST USER\n",
    "# =============================\n",
    "test_user = {\n",
    "    'Education': 'M.Tech',\n",
    "    'Skill no. 1': 'Remote Sensing',\n",
    "    'Skill no. 2': 'Biostatistics',\n",
    "    'Skill no. 3': 'Power BI',\n",
    "    'Interest': 'Research',\n",
    "    'Location': 'Uttar Pradesh'\n",
    "}\n",
    "\n",
    "# Run prediction\n",
    "print(predict_internship(test_user))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059aed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
